{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0233b3-dcc3-4de3-9f6a-d08d22d2f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer, GPT2LMHeadModel \n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch_geometric.nn import GCNConv, SimpleConv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c6eee-deee-45fa-bfda-b781b6fffd63",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a905e9-8904-4ca6-b4a9-5611ced2aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class ModuleHook:\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.module = None\n",
    "        self.features = []\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.module = module\n",
    "        self.features.append(output.detach())\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "        \n",
    "        \n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dea4c2-2edb-4d87-af1d-890cd61ea39e",
   "metadata": {},
   "source": [
    "## Load CoNLL POS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7f6542-96ee-4fcb-aa6b-0080a3d1f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/n/home04/yidachen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac451360e6e4aa7bb8a0f0070571e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /n/home04/yidachen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-14ddfd0b473a8b77.arrow\n",
      "Loading cached processed dataset at /n/home04/yidachen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-bcd22b6260ce4441.arrow\n",
      "Loading cached processed dataset at /n/home04/yidachen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-e81651b02000ac4a.arrow\n"
     ]
    }
   ],
   "source": [
    "task = \"chunk\" \n",
    "datasets = load_dataset(\"conll2003\")\n",
    "label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
    "\n",
    "model_checkpoint = \"gpt2\"\n",
    "batch_size = 16\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "label_all_tokens = True\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db675786-ce53-4a9f-8240-a5eb30d5c9ad",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cab50c-67e4-4128-9115-5e2111143820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_probe import GCNProbe, GCNNonlinearProbe, MLPProbe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36094d-33d5-4d95-9542-d5fff9f2ea71",
   "metadata": {},
   "source": [
    "## Create Train & Test Split for Probing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96c877-041b-45b4-b15d-ed87c459bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "split = \"test\"\n",
    "num_samples = len(datasets[split])\n",
    "train_portion = 0.8\n",
    "\n",
    "sampled_indices = np.random.choice(np.arange(len(tokenized_datasets[split])),\n",
    "                                   num_samples, \n",
    "                                   replace=False)\n",
    "\n",
    "\n",
    "sampled_train = np.random.choice(np.arange(len(sampled_indices)), \n",
    "                                 int(num_samples * train_portion), \n",
    "                                 replace=False)\n",
    "\n",
    "\n",
    "sampled_test = np.setdiff1d(np.arange(len(sampled_indices)), sampled_train)\n",
    "\n",
    "\n",
    "train_mask = np.array([True] * num_samples)\n",
    "train_mask[sampled_test] = False\n",
    "\n",
    "\n",
    "test_mask = np.array([True] * num_samples)\n",
    "test_mask[sampled_train] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040456fd-9622-432e-b741-6068fe74c88b",
   "metadata": {},
   "source": [
    "## Create Unweighted Directed Graph of Text using pretrained GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb72f04b-c944-4dfa-ab2b-deb9050022b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e002ccb76620474784ed00d0b87ab751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cuda\")\n",
    "        \n",
    "threshold = 0.2\n",
    "layer = 4   \n",
    "    \n",
    "all_graphs = {}\n",
    "for layer in range(12):\n",
    "    all_graphs[layer] = {}\n",
    "    for head in range(12):\n",
    "        all_graphs[layer][head] = []\n",
    "    \n",
    "# graphs = []\n",
    "\n",
    "\n",
    "for i in tqdm(sampled_indices):\n",
    "    features = OrderedDict()\n",
    "    for name, module in model.named_modules():\n",
    "        if \"c_attn\" in name:\n",
    "            features[name] = ModuleHook(module)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids = torch.Tensor(tokenized_datasets[split][\"input_ids\"][i]).type(torch.long).to(\"cuda\"),\n",
    "                       attention_mask = torch.Tensor(tokenized_datasets[split][\"attention_mask\"][i]).to(\"cuda\"),\n",
    "                       output_attentions = True,\n",
    "                       output_hidden_states = True)\n",
    "\n",
    "\n",
    "    for feature in features.values():\n",
    "        feature.close()\n",
    "\n",
    "    y = tokenized_datasets[split][\"labels\"][i]\n",
    "    for layer in range(12):\n",
    "        value_features = features[f'transformer.h.{layer}.attn.c_attn'].features[0].split(768, dim=2)[-1][0].clone()\n",
    "        for head in range(12):\n",
    "            weighted_adj_matrix = output[\"attentions\"][layer][0][head].detach().cpu()\n",
    "\n",
    "            # node_features = output[\"hidden_states\"][layer - 1][0].detach().cpu()\n",
    "\n",
    "            node_features = value_features[:, head * 64: (head + 1) * 64]\n",
    "\n",
    "            adj_matrix = weighted_adj_matrix > threshold\n",
    "\n",
    "            edge_index = adj_matrix.detach().clone().cpu().nonzero().t().contiguous().type(torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "            all_graphs[layer][head].append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e393ca-7184-44cd-a39d-aab80eb83a8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and Test Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb6a98a-e5dc-4eff-ae13-b8789849ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out, torch.Tensor(data.y).type(torch.long))  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred == torch.Tensor(data.y)  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(len(data.batch))  # Derive ratio of correct predictions.\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfc900-e778-4e63-8136-f3dcb8725263",
   "metadata": {},
   "source": [
    "## Train Probe on Graph representations of Text at 144 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60bd805-7841-44a0-9e4c-e8548d305970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418cdd7d45104d12974f001e7bd81f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- layer 0 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.9046\n",
      "Train Accuracy: 0.6533\n",
      "Test Accuracy: 0.6552\n",
      "------------------------- layer 0 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.7039\n",
      "Train Accuracy: 0.7058\n",
      "Test Accuracy: 0.7116\n",
      "------------------------- layer 0 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.8404\n",
      "Train Accuracy: 0.6658\n",
      "Test Accuracy: 0.6658\n",
      "------------------------- layer 0 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.8166\n",
      "Train Accuracy: 0.6804\n",
      "Test Accuracy: 0.6834\n",
      "------------------------- layer 0 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.9305\n",
      "Train Accuracy: 0.6520\n",
      "Test Accuracy: 0.6538\n",
      "------------------------- layer 0 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.8131\n",
      "Train Accuracy: 0.6892\n",
      "Test Accuracy: 0.6949\n",
      "------------------------- layer 0 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.9109\n",
      "Train Accuracy: 0.6467\n",
      "Test Accuracy: 0.6425\n",
      "------------------------- layer 0 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.9710\n",
      "Train Accuracy: 0.6089\n",
      "Test Accuracy: 0.6138\n",
      "------------------------- layer 0 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.9092\n",
      "Train Accuracy: 0.6510\n",
      "Test Accuracy: 0.6535\n",
      "------------------------- layer 0 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.7685\n",
      "Train Accuracy: 0.6989\n",
      "Test Accuracy: 0.7038\n",
      "------------------------- layer 0 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.7617\n",
      "Train Accuracy: 0.6969\n",
      "Test Accuracy: 0.6945\n",
      "------------------------- layer 0 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.8539\n",
      "Train Accuracy: 0.6745\n",
      "Test Accuracy: 0.6712\n",
      "------------------------- layer 1 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.9363\n",
      "Train Accuracy: 0.6294\n",
      "Test Accuracy: 0.6280\n",
      "------------------------- layer 1 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.7962\n",
      "Train Accuracy: 0.7031\n",
      "Test Accuracy: 0.6994\n",
      "------------------------- layer 1 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.8601\n",
      "Train Accuracy: 0.6766\n",
      "Test Accuracy: 0.6799\n",
      "------------------------- layer 1 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.8460\n",
      "Train Accuracy: 0.6935\n",
      "Test Accuracy: 0.6933\n",
      "------------------------- layer 1 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.6956\n",
      "Train Accuracy: 0.7371\n",
      "Test Accuracy: 0.7423\n",
      "------------------------- layer 1 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.8452\n",
      "Train Accuracy: 0.6696\n",
      "Test Accuracy: 0.6713\n",
      "------------------------- layer 1 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.9002\n",
      "Train Accuracy: 0.6585\n",
      "Test Accuracy: 0.6601\n",
      "------------------------- layer 1 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.7873\n",
      "Train Accuracy: 0.6981\n",
      "Test Accuracy: 0.7018\n",
      "------------------------- layer 1 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.8162\n",
      "Train Accuracy: 0.6936\n",
      "Test Accuracy: 0.6903\n",
      "------------------------- layer 1 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.7852\n",
      "Train Accuracy: 0.6998\n",
      "Test Accuracy: 0.6971\n",
      "------------------------- layer 1 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.8246\n",
      "Train Accuracy: 0.6875\n",
      "Test Accuracy: 0.6853\n",
      "------------------------- layer 1 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.7146\n",
      "Train Accuracy: 0.7221\n",
      "Test Accuracy: 0.7273\n",
      "------------------------- layer 2 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.8599\n",
      "Train Accuracy: 0.6802\n",
      "Test Accuracy: 0.6816\n",
      "------------------------- layer 2 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.9546\n",
      "Train Accuracy: 0.6475\n",
      "Test Accuracy: 0.6531\n",
      "------------------------- layer 2 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.9650\n",
      "Train Accuracy: 0.6267\n",
      "Test Accuracy: 0.6249\n",
      "------------------------- layer 2 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.9374\n",
      "Train Accuracy: 0.6419\n",
      "Test Accuracy: 0.6474\n",
      "------------------------- layer 2 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 1.0953\n",
      "Train Accuracy: 0.5753\n",
      "Test Accuracy: 0.5670\n",
      "------------------------- layer 2 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.9304\n",
      "Train Accuracy: 0.6448\n",
      "Test Accuracy: 0.6451\n",
      "------------------------- layer 2 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.7881\n",
      "Train Accuracy: 0.7002\n",
      "Test Accuracy: 0.7050\n",
      "------------------------- layer 2 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.8388\n",
      "Train Accuracy: 0.6847\n",
      "Test Accuracy: 0.6822\n",
      "------------------------- layer 2 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.9994\n",
      "Train Accuracy: 0.6340\n",
      "Test Accuracy: 0.6411\n",
      "------------------------- layer 2 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.8837\n",
      "Train Accuracy: 0.6723\n",
      "Test Accuracy: 0.6676\n",
      "------------------------- layer 2 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.6841\n",
      "Train Accuracy: 0.7466\n",
      "Test Accuracy: 0.7461\n",
      "------------------------- layer 2 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.7571\n",
      "Train Accuracy: 0.7252\n",
      "Test Accuracy: 0.7318\n",
      "------------------------- layer 3 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.6183\n",
      "Train Accuracy: 0.7930\n",
      "Test Accuracy: 0.7909\n",
      "------------------------- layer 3 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.8788\n",
      "Train Accuracy: 0.6811\n",
      "Test Accuracy: 0.6859\n",
      "------------------------- layer 3 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.8691\n",
      "Train Accuracy: 0.6597\n",
      "Test Accuracy: 0.6661\n",
      "------------------------- layer 3 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.8999\n",
      "Train Accuracy: 0.6678\n",
      "Test Accuracy: 0.6645\n",
      "------------------------- layer 3 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.6804\n",
      "Train Accuracy: 0.7586\n",
      "Test Accuracy: 0.7671\n",
      "------------------------- layer 3 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.7983\n",
      "Train Accuracy: 0.7019\n",
      "Test Accuracy: 0.7060\n",
      "------------------------- layer 3 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.7909\n",
      "Train Accuracy: 0.7107\n",
      "Test Accuracy: 0.7123\n",
      "------------------------- layer 3 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.9122\n",
      "Train Accuracy: 0.6745\n",
      "Test Accuracy: 0.6715\n",
      "------------------------- layer 3 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.9749\n",
      "Train Accuracy: 0.6345\n",
      "Test Accuracy: 0.6321\n",
      "------------------------- layer 3 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.8807\n",
      "Train Accuracy: 0.6693\n",
      "Test Accuracy: 0.6675\n",
      "------------------------- layer 3 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.6630\n",
      "Train Accuracy: 0.7765\n",
      "Test Accuracy: 0.7756\n",
      "------------------------- layer 3 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.9525\n",
      "Train Accuracy: 0.6479\n",
      "Test Accuracy: 0.6529\n",
      "------------------------- layer 4 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 1.0694\n",
      "Train Accuracy: 0.5946\n",
      "Test Accuracy: 0.5946\n",
      "------------------------- layer 4 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 1.0444\n",
      "Train Accuracy: 0.6094\n",
      "Test Accuracy: 0.6059\n",
      "------------------------- layer 4 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.9307\n",
      "Train Accuracy: 0.6644\n",
      "Test Accuracy: 0.6615\n",
      "------------------------- layer 4 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.8365\n",
      "Train Accuracy: 0.7019\n",
      "Test Accuracy: 0.7006\n",
      "------------------------- layer 4 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.7087\n",
      "Train Accuracy: 0.7482\n",
      "Test Accuracy: 0.7500\n",
      "------------------------- layer 4 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.9103\n",
      "Train Accuracy: 0.6708\n",
      "Test Accuracy: 0.6587\n",
      "------------------------- layer 4 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.6840\n",
      "Train Accuracy: 0.7554\n",
      "Test Accuracy: 0.7579\n",
      "------------------------- layer 4 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.9779\n",
      "Train Accuracy: 0.6665\n",
      "Test Accuracy: 0.6569\n",
      "------------------------- layer 4 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.8117\n",
      "Train Accuracy: 0.7108\n",
      "Test Accuracy: 0.7070\n",
      "------------------------- layer 4 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.9325\n",
      "Train Accuracy: 0.6553\n",
      "Test Accuracy: 0.6533\n",
      "------------------------- layer 4 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.7924\n",
      "Train Accuracy: 0.7081\n",
      "Test Accuracy: 0.7029\n",
      "------------------------- layer 4 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.7196\n",
      "Train Accuracy: 0.7466\n",
      "Test Accuracy: 0.7435\n",
      "------------------------- layer 5 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.7641\n",
      "Train Accuracy: 0.7456\n",
      "Test Accuracy: 0.7472\n",
      "------------------------- layer 5 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.6963\n",
      "Train Accuracy: 0.7427\n",
      "Test Accuracy: 0.7429\n",
      "------------------------- layer 5 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.9036\n",
      "Train Accuracy: 0.6903\n",
      "Test Accuracy: 0.6866\n",
      "------------------------- layer 5 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.9644\n",
      "Train Accuracy: 0.6467\n",
      "Test Accuracy: 0.6401\n",
      "------------------------- layer 5 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.9922\n",
      "Train Accuracy: 0.6501\n",
      "Test Accuracy: 0.6478\n",
      "------------------------- layer 5 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.8178\n",
      "Train Accuracy: 0.7175\n",
      "Test Accuracy: 0.7233\n",
      "------------------------- layer 5 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.8209\n",
      "Train Accuracy: 0.6995\n",
      "Test Accuracy: 0.6913\n",
      "------------------------- layer 5 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.9374\n",
      "Train Accuracy: 0.6546\n",
      "Test Accuracy: 0.6545\n",
      "------------------------- layer 5 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.7660\n",
      "Train Accuracy: 0.7356\n",
      "Test Accuracy: 0.7334\n",
      "------------------------- layer 5 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.7178\n",
      "Train Accuracy: 0.7483\n",
      "Test Accuracy: 0.7452\n",
      "------------------------- layer 5 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 1.0108\n",
      "Train Accuracy: 0.6165\n",
      "Test Accuracy: 0.6092\n",
      "------------------------- layer 5 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 1.0430\n",
      "Train Accuracy: 0.6065\n",
      "Test Accuracy: 0.6008\n",
      "------------------------- layer 6 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 1.0901\n",
      "Train Accuracy: 0.5910\n",
      "Test Accuracy: 0.5815\n",
      "------------------------- layer 6 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.7745\n",
      "Train Accuracy: 0.7097\n",
      "Test Accuracy: 0.7069\n",
      "------------------------- layer 6 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.8488\n",
      "Train Accuracy: 0.6984\n",
      "Test Accuracy: 0.6953\n",
      "------------------------- layer 6 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 1.0619\n",
      "Train Accuracy: 0.6019\n",
      "Test Accuracy: 0.6069\n",
      "------------------------- layer 6 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 1.1284\n",
      "Train Accuracy: 0.5723\n",
      "Test Accuracy: 0.5691\n",
      "------------------------- layer 6 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 0.7584\n",
      "Train Accuracy: 0.7481\n",
      "Test Accuracy: 0.7482\n",
      "------------------------- layer 6 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.8434\n",
      "Train Accuracy: 0.6981\n",
      "Test Accuracy: 0.6939\n",
      "------------------------- layer 6 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 1.0134\n",
      "Train Accuracy: 0.6260\n",
      "Test Accuracy: 0.6273\n",
      "------------------------- layer 6 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.9268\n",
      "Train Accuracy: 0.6790\n",
      "Test Accuracy: 0.6745\n",
      "------------------------- layer 6 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.7300\n",
      "Train Accuracy: 0.7292\n",
      "Test Accuracy: 0.7269\n",
      "------------------------- layer 6 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.8411\n",
      "Train Accuracy: 0.7062\n",
      "Test Accuracy: 0.7075\n",
      "------------------------- layer 6 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 1.0167\n",
      "Train Accuracy: 0.6254\n",
      "Test Accuracy: 0.6232\n",
      "------------------------- layer 7 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 1.1043\n",
      "Train Accuracy: 0.5810\n",
      "Test Accuracy: 0.5815\n",
      "------------------------- layer 7 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 1.0463\n",
      "Train Accuracy: 0.5991\n",
      "Test Accuracy: 0.5971\n",
      "------------------------- layer 7 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.8525\n",
      "Train Accuracy: 0.6758\n",
      "Test Accuracy: 0.6698\n",
      "------------------------- layer 7 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 0.9060\n",
      "Train Accuracy: 0.6598\n",
      "Test Accuracy: 0.6650\n",
      "------------------------- layer 7 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.8941\n",
      "Train Accuracy: 0.6896\n",
      "Test Accuracy: 0.6862\n",
      "------------------------- layer 7 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 1.2116\n",
      "Train Accuracy: 0.5381\n",
      "Test Accuracy: 0.5281\n",
      "------------------------- layer 7 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.8306\n",
      "Train Accuracy: 0.6982\n",
      "Test Accuracy: 0.6983\n",
      "------------------------- layer 7 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.7982\n",
      "Train Accuracy: 0.7267\n",
      "Test Accuracy: 0.7246\n",
      "------------------------- layer 7 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 1.1359\n",
      "Train Accuracy: 0.5749\n",
      "Test Accuracy: 0.5708\n",
      "------------------------- layer 7 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 0.9936\n",
      "Train Accuracy: 0.6378\n",
      "Test Accuracy: 0.6298\n",
      "------------------------- layer 7 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.8623\n",
      "Train Accuracy: 0.6857\n",
      "Test Accuracy: 0.6792\n",
      "------------------------- layer 7 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.7139\n",
      "Train Accuracy: 0.7404\n",
      "Test Accuracy: 0.7382\n",
      "------------------------- layer 8 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.8274\n",
      "Train Accuracy: 0.6989\n",
      "Test Accuracy: 0.7026\n",
      "------------------------- layer 8 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 0.8246\n",
      "Train Accuracy: 0.6866\n",
      "Test Accuracy: 0.6862\n",
      "------------------------- layer 8 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.9479\n",
      "Train Accuracy: 0.6476\n",
      "Test Accuracy: 0.6471\n",
      "------------------------- layer 8 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 1.0646\n",
      "Train Accuracy: 0.6201\n",
      "Test Accuracy: 0.6215\n",
      "------------------------- layer 8 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 1.0588\n",
      "Train Accuracy: 0.5931\n",
      "Test Accuracy: 0.5905\n",
      "------------------------- layer 8 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 1.1027\n",
      "Train Accuracy: 0.5834\n",
      "Test Accuracy: 0.5850\n",
      "------------------------- layer 8 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 0.8950\n",
      "Train Accuracy: 0.6857\n",
      "Test Accuracy: 0.6823\n",
      "------------------------- layer 8 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 1.1928\n",
      "Train Accuracy: 0.5383\n",
      "Test Accuracy: 0.5336\n",
      "------------------------- layer 8 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 1.1889\n",
      "Train Accuracy: 0.5416\n",
      "Test Accuracy: 0.5400\n",
      "------------------------- layer 8 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 1.0094\n",
      "Train Accuracy: 0.6294\n",
      "Test Accuracy: 0.6358\n",
      "------------------------- layer 8 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 0.8192\n",
      "Train Accuracy: 0.6995\n",
      "Test Accuracy: 0.6993\n",
      "------------------------- layer 8 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.9708\n",
      "Train Accuracy: 0.6318\n",
      "Test Accuracy: 0.6410\n",
      "------------------------- layer 9 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 1.0758\n",
      "Train Accuracy: 0.5867\n",
      "Test Accuracy: 0.5815\n",
      "------------------------- layer 9 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 1.0565\n",
      "Train Accuracy: 0.5985\n",
      "Test Accuracy: 0.5919\n",
      "------------------------- layer 9 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 1.1541\n",
      "Train Accuracy: 0.5529\n",
      "Test Accuracy: 0.5461\n",
      "------------------------- layer 9 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 1.2277\n",
      "Train Accuracy: 0.5145\n",
      "Test Accuracy: 0.5172\n",
      "------------------------- layer 9 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.9063\n",
      "Train Accuracy: 0.6828\n",
      "Test Accuracy: 0.6809\n",
      "------------------------- layer 9 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 1.0547\n",
      "Train Accuracy: 0.6002\n",
      "Test Accuracy: 0.5932\n",
      "------------------------- layer 9 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 1.0403\n",
      "Train Accuracy: 0.6143\n",
      "Test Accuracy: 0.6156\n",
      "------------------------- layer 9 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 1.0317\n",
      "Train Accuracy: 0.6097\n",
      "Test Accuracy: 0.6090\n",
      "------------------------- layer 9 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.9536\n",
      "Train Accuracy: 0.6502\n",
      "Test Accuracy: 0.6507\n",
      "------------------------- layer 9 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 1.1178\n",
      "Train Accuracy: 0.5824\n",
      "Test Accuracy: 0.5735\n",
      "------------------------- layer 9 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 1.1460\n",
      "Train Accuracy: 0.5558\n",
      "Test Accuracy: 0.5533\n",
      "------------------------- layer 9 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 0.8165\n",
      "Train Accuracy: 0.7021\n",
      "Test Accuracy: 0.7036\n",
      "------------------------- layer 10 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 1.2281\n",
      "Train Accuracy: 0.5222\n",
      "Test Accuracy: 0.5187\n",
      "------------------------- layer 10 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 1.1311\n",
      "Train Accuracy: 0.5802\n",
      "Test Accuracy: 0.5820\n",
      "------------------------- layer 10 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 0.9650\n",
      "Train Accuracy: 0.6356\n",
      "Test Accuracy: 0.6339\n",
      "------------------------- layer 10 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 1.0951\n",
      "Train Accuracy: 0.5837\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 10 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 1.0261\n",
      "Train Accuracy: 0.6182\n",
      "Test Accuracy: 0.6193\n",
      "------------------------- layer 10 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 1.0906\n",
      "Train Accuracy: 0.5765\n",
      "Test Accuracy: 0.5701\n",
      "------------------------- layer 10 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 1.1885\n",
      "Train Accuracy: 0.5489\n",
      "Test Accuracy: 0.5564\n",
      "------------------------- layer 10 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 0.9819\n",
      "Train Accuracy: 0.6242\n",
      "Test Accuracy: 0.6219\n",
      "------------------------- layer 10 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 0.8188\n",
      "Train Accuracy: 0.6817\n",
      "Test Accuracy: 0.6757\n",
      "------------------------- layer 10 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 1.1362\n",
      "Train Accuracy: 0.5631\n",
      "Test Accuracy: 0.5688\n",
      "------------------------- layer 10 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 1.0351\n",
      "Train Accuracy: 0.6105\n",
      "Test Accuracy: 0.6106\n",
      "------------------------- layer 10 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 1.2308\n",
      "Train Accuracy: 0.5360\n",
      "Test Accuracy: 0.5336\n",
      "------------------------- layer 11 head 0 -------------------------\n",
      "Epoch: 1000, Loss: 0.9850\n",
      "Train Accuracy: 0.6318\n",
      "Test Accuracy: 0.6272\n",
      "------------------------- layer 11 head 1 -------------------------\n",
      "Epoch: 1000, Loss: 1.0412\n",
      "Train Accuracy: 0.6064\n",
      "Test Accuracy: 0.6046\n",
      "------------------------- layer 11 head 2 -------------------------\n",
      "Epoch: 1000, Loss: 1.2053\n",
      "Train Accuracy: 0.5476\n",
      "Test Accuracy: 0.5468\n",
      "------------------------- layer 11 head 3 -------------------------\n",
      "Epoch: 1000, Loss: 1.4128\n",
      "Train Accuracy: 0.4537\n",
      "Test Accuracy: 0.4510\n",
      "------------------------- layer 11 head 4 -------------------------\n",
      "Epoch: 1000, Loss: 0.9042\n",
      "Train Accuracy: 0.6564\n",
      "Test Accuracy: 0.6563\n",
      "------------------------- layer 11 head 5 -------------------------\n",
      "Epoch: 1000, Loss: 2.7413\n",
      "Train Accuracy: 0.4927\n",
      "Test Accuracy: 0.4984\n",
      "------------------------- layer 11 head 6 -------------------------\n",
      "Epoch: 1000, Loss: 1.0135\n",
      "Train Accuracy: 0.6173\n",
      "Test Accuracy: 0.6148\n",
      "------------------------- layer 11 head 7 -------------------------\n",
      "Epoch: 1000, Loss: 1.0438\n",
      "Train Accuracy: 0.6148\n",
      "Test Accuracy: 0.6140\n",
      "------------------------- layer 11 head 8 -------------------------\n",
      "Epoch: 1000, Loss: 3.5285\n",
      "Train Accuracy: 0.4418\n",
      "Test Accuracy: 0.4540\n",
      "------------------------- layer 11 head 9 -------------------------\n",
      "Epoch: 1000, Loss: 1.1820\n",
      "Train Accuracy: 0.5564\n",
      "Test Accuracy: 0.5606\n",
      "------------------------- layer 11 head 10 -------------------------\n",
      "Epoch: 1000, Loss: 1.2093\n",
      "Train Accuracy: 0.5418\n",
      "Test Accuracy: 0.5319\n",
      "------------------------- layer 11 head 11 -------------------------\n",
      "Epoch: 1000, Loss: 1.2568\n",
      "Train Accuracy: 0.4980\n",
      "Test Accuracy: 0.4951\n"
     ]
    }
   ],
   "source": [
    "train_accs = {}\n",
    "test_accs = {}\n",
    "\n",
    "\n",
    "for layer in tqdm(range(0, 12)):\n",
    "    train_accs[layer] = {}\n",
    "    test_accs[layer] = {}\n",
    "    for head in range(0, 12):\n",
    "        probe = GCNProbe(64, 23).to(\"cuda\")\n",
    "        optimizer = torch.optim.Adam(probe.parameters(), lr=0.05)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_data = Batch.from_data_list([all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if train_mask[i]])\n",
    "        train_data.y = torch.Tensor(np.concatenate(train_data.y).ravel()).type(torch.long).to(\"cuda\")\n",
    "\n",
    "        test_data = Batch.from_data_list([all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if test_mask[i]])\n",
    "        test_data.y = torch.Tensor(np.concatenate(test_data.y).ravel()).type(torch.long).to(\"cuda\")\n",
    "\n",
    "        for epoch in range(1, 1001):\n",
    "            loss = train(probe, optimizer, criterion, train_data)\n",
    "            train_acc = test(probe, train_data)\n",
    "\n",
    "        print(\"-\" * 25 + f\" layer {layer} head {head} \" + \"-\" * 25)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        print(f'Train Accuracy: {train_acc:.4f}')\n",
    "\n",
    "\n",
    "        test_acc = test(probe, test_data)\n",
    "        print(f'Test Accuracy: {test_acc:.4f}')\n",
    "        \n",
    "        train_accs[layer][head] = train_acc\n",
    "        test_accs[layer][head] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d543d-03ed-4f5d-836f-384a58baf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_utils import heatmap, annotate_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "score_matrix = []\n",
    "\n",
    "for layer in range(12):\n",
    "    score_matrix.append([])\n",
    "    for head in range(12):\n",
    "        score_matrix[layer].append(test_accs[layer][head])\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "im, cbar = heatmap(np.array(score_matrix), [f\"Layer {i + 1}\" for i in range(12)], [f\"H {i + 1}\" for i in range(12)],\n",
    "        cmap=\"bwr\")\n",
    "\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(18)\n",
    "\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.2f} \", fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660bd60-9568-4561-8266-924b2090a240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diffusion]",
   "language": "python",
   "name": "conda-env-.conda-diffusion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
