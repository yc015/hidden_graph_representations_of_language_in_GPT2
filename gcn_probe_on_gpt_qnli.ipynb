{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e74613-9c6b-497a-8c79-abae70418697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer, GPT2LMHeadModel \n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch_geometric.nn import GCNConv, SimpleConv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb026a-f35e-4c75-a210-7357d842bc38",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a9ab4b-daee-4c77-a78d-d52b700a96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class ModuleHook:\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.module = None\n",
    "        self.features = []\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.module = module\n",
    "        self.features.append(output.detach())\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "        \n",
    "        \n",
    "def combine_data(examples):\n",
    "    output = {\"sentence\": []}\n",
    "    for i in range(len(examples)):\n",
    "        output[\"sentence\"].append(examples[\"premise\"][i] + examples[\"hypothesis\"][i])\n",
    "    return output\n",
    "        \n",
    "def tokenize_data(examples):\n",
    "    sentence = [\"Question: \" + examples[\"question\"][i] + \"\\nIs answer in the following sentences: \" + examples[\"sentence\"][i] for i in range(len(examples[\"sentence\"]))]\n",
    "    tokenized_inputs = tokenizer(sentence, truncation=True)\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb83b7c-79da-43d3-bb28-372ef5572006",
   "metadata": {},
   "source": [
    "## Load in QNLI dataset from GLUE benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fdd016-8d21-4a99-8137-1dab4f9c653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/n/home04/yidachen/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38b615ba5764904a6ad76af2427662b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "# task = \"mnli\"\n",
    "task = \"qnli\"\n",
    "\n",
    "actual_task = \"mnli\" if task == \"mnli-mm\" else task\n",
    "dataset = load_dataset(\"glue\", actual_task)\n",
    "metric = load_metric('glue', actual_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd416c9-99ea-4db5-9cb1-c9eecf2eb40f",
   "metadata": {},
   "source": [
    "## Tokenize the Question and Document into sequences of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2319367-5e22-4e69-b774-9239fb935a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When did the third Digimon series begin?',\n",
       " 'sentence': 'Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese.',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"gpt2\"\n",
    "batch_size = 16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8db383-6c7c-4047-a11b-c523da2e08fe",
   "metadata": {},
   "source": [
    "## Create Train & Test Split for Probing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb0275-b926-4671-ad9f-b6b4060ea71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# split = \"validation_matched\"\n",
    "split = \"validation\"\n",
    "# num_samples = len(dataset[\"validation_matched\"])\n",
    "num_samples = 1000\n",
    "train_portion = 0.8\n",
    "\n",
    "sampled_indices = np.random.choice(np.arange(len(tokenized_datasets[split])),\n",
    "                                   num_samples, \n",
    "                                   replace=False)\n",
    "\n",
    "\n",
    "sampled_train = np.random.choice(np.arange(len(sampled_indices)), \n",
    "                                 int(num_samples * train_portion), \n",
    "                                 replace=False)\n",
    "\n",
    "\n",
    "sampled_test = np.setdiff1d(np.arange(len(sampled_indices)), sampled_train)\n",
    "\n",
    "\n",
    "train_mask = np.array([True] * num_samples)\n",
    "train_mask[sampled_test] = False\n",
    "\n",
    "\n",
    "test_mask = np.array([True] * num_samples)\n",
    "test_mask[sampled_train] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264dca6-8293-44b3-b52c-66de2e6f3b11",
   "metadata": {},
   "source": [
    "## Create Unweighted Directed Graph Representation of Text from GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb21d00d-d956-498c-876a-7c2b35be6a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6a63c7980a48e4a8c91ae0598bc269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(\"cuda\")\n",
    "        \n",
    "threshold = 0.2 \n",
    "    \n",
    "all_graphs = {}\n",
    "for layer in range(12):\n",
    "    all_graphs[layer] = {}\n",
    "    for head in range(12):\n",
    "        all_graphs[layer][head] = []\n",
    "    \n",
    "# graphs = []\n",
    "\n",
    "for i in tqdm(sampled_indices):\n",
    "    features = OrderedDict()\n",
    "    for name, module in model.named_modules():\n",
    "        if \"c_attn\" in name:\n",
    "            features[name] = ModuleHook(module)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids = torch.Tensor(tokenized_datasets[split][\"input_ids\"][i]).type(torch.long).to(\"cuda\"),\n",
    "                       attention_mask = torch.Tensor(tokenized_datasets[split][\"attention_mask\"][i]).to(\"cuda\"),\n",
    "                       output_attentions = True,\n",
    "                       output_hidden_states = True)\n",
    "\n",
    "\n",
    "    for feature in features.values():\n",
    "        feature.close()\n",
    "\n",
    "    y = tokenized_datasets[split][\"label\"][i]\n",
    "    for layer in range(12):\n",
    "        value_features = features[f'transformer.h.{layer}.attn.c_attn'].features[0].split(768, dim=2)[-1][0].clone()\n",
    "        for head in range(12):\n",
    "            weighted_adj_matrix = output[\"attentions\"][layer][0][head].detach().cpu()\n",
    "\n",
    "            # node_features = output[\"hidden_states\"][layer - 1][0].detach().cpu()\n",
    "\n",
    "            node_features = value_features[:, head * 64: (head + 1) * 64]\n",
    "\n",
    "            adj_matrix = weighted_adj_matrix > threshold\n",
    "\n",
    "            edge_index = adj_matrix.detach().clone().cpu().nonzero().t().contiguous().type(torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "            all_graphs[layer][head].append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c661c92-d34c-4924-9bf8-9c2f5c3a58b2",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c70d5b-5d32-4b99-a443-fc7c83d18265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_probe import GCNProbe, GCNNonlinearProbe, MLPProbe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f731e-5c32-4722-b52b-8423bf4009fc",
   "metadata": {},
   "source": [
    "## Create Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697f9a99-3c08-45a8-a00e-01f4a058bb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "metric = load_metric('glue', actual_task)\n",
    "\n",
    "train_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if train_mask[i]]\n",
    "test_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if test_mask[i]]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fec6c-1f6a-41b1-9ae4-5fdbb8c27313",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and Test Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39aa1cf-57fc-4580-bc12-3e327e23268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader):\n",
    "    model.train()\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y.to(\"cuda\"))  # Compute the loss.\n",
    "        \n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    return loss\n",
    "        \n",
    "        \n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    preds = torch.Tensor([]).to(\"cuda\")\n",
    "    refs = torch.Tensor([]).to(\"cuda\")\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y.to(\"cuda\")).sum())  # Check against ground-truth labels.\n",
    "        preds = torch.concat([preds, pred])\n",
    "        refs = torch.concat([refs, data.y.to(\"cuda\")])\n",
    "        \n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f1d60-856d-40fb-b8a9-d649182c70e3",
   "metadata": {},
   "source": [
    "## Convert large dataset into sets of mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24825fe2-5930-4ea3-b329-760e2e3a517e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[907, 64], edge_index=[2, 1057], y=[16], batch=[907], ptr=[17])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[976, 64], edge_index=[2, 1138], y=[16], batch=[976], ptr=[17])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[942, 64], edge_index=[2, 1086], y=[16], batch=[942], ptr=[17])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[865, 64], edge_index=[2, 1023], y=[16], batch=[865], ptr=[17])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[928, 64], edge_index=[2, 1089], y=[16], batch=[928], ptr=[17])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[952, 64], edge_index=[2, 1113], y=[16], batch=[952], ptr=[17])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[967, 64], edge_index=[2, 1129], y=[16], batch=[967], ptr=[17])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[940, 64], edge_index=[2, 1078], y=[16], batch=[940], ptr=[17])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[929, 64], edge_index=[2, 1135], y=[16], batch=[929], ptr=[17])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[804, 64], edge_index=[2, 982], y=[16], batch=[804], ptr=[17])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[919, 64], edge_index=[2, 1131], y=[16], batch=[919], ptr=[17])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[997, 64], edge_index=[2, 1186], y=[16], batch=[997], ptr=[17])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[500, 64], edge_index=[2, 608], y=[8], batch=[500], ptr=[9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if train_mask[i]]\n",
    "test_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if test_mask[i]]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(test_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c604f9-153d-43f6-abe2-e5aac0c7c678",
   "metadata": {},
   "source": [
    "## Train Probe on Graph representations of Text at 144 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d972da-a7b0-4b83-9b91-f66d5343a947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28ce8050053446d9685419f7f92375d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- layer 0 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.7218\n",
      "Train Accuracy: 0.6175\n",
      "Test Accuracy: 0.5250\n",
      "------------------------- layer 0 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6160\n",
      "Train Accuracy: 0.6325\n",
      "Test Accuracy: 0.5800\n",
      "------------------------- layer 0 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6767\n",
      "Train Accuracy: 0.6150\n",
      "Test Accuracy: 0.4950\n",
      "------------------------- layer 0 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.6283\n",
      "Train Accuracy: 0.6112\n",
      "Test Accuracy: 0.5300\n",
      "------------------------- layer 0 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6240\n",
      "Train Accuracy: 0.6388\n",
      "Test Accuracy: 0.5750\n",
      "------------------------- layer 0 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.6864\n",
      "Train Accuracy: 0.6112\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 0 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.6803\n",
      "Train Accuracy: 0.6312\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 0 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.6392\n",
      "Train Accuracy: 0.6388\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 0 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6535\n",
      "Train Accuracy: 0.6300\n",
      "Test Accuracy: 0.5300\n",
      "------------------------- layer 0 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.6700\n",
      "Train Accuracy: 0.6038\n",
      "Test Accuracy: 0.4950\n",
      "------------------------- layer 0 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.6582\n",
      "Train Accuracy: 0.6400\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 0 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.7014\n",
      "Train Accuracy: 0.6138\n",
      "Test Accuracy: 0.5450\n",
      "------------------------- layer 1 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.5700\n",
      "Train Accuracy: 0.7137\n",
      "Test Accuracy: 0.6900\n",
      "------------------------- layer 1 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6496\n",
      "Train Accuracy: 0.7000\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 1 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.4771\n",
      "Train Accuracy: 0.6887\n",
      "Test Accuracy: 0.6450\n",
      "------------------------- layer 1 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5655\n",
      "Train Accuracy: 0.6412\n",
      "Test Accuracy: 0.5450\n",
      "------------------------- layer 1 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6479\n",
      "Train Accuracy: 0.7025\n",
      "Test Accuracy: 0.7000\n",
      "------------------------- layer 1 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.5173\n",
      "Train Accuracy: 0.6925\n",
      "Test Accuracy: 0.7250\n",
      "------------------------- layer 1 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.6724\n",
      "Train Accuracy: 0.6512\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 1 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5193\n",
      "Train Accuracy: 0.7225\n",
      "Test Accuracy: 0.6950\n",
      "------------------------- layer 1 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.5192\n",
      "Train Accuracy: 0.6700\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 1 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5149\n",
      "Train Accuracy: 0.6575\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 1 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.6475\n",
      "Train Accuracy: 0.6675\n",
      "Test Accuracy: 0.6000\n",
      "------------------------- layer 1 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.5933\n",
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 2 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.6490\n",
      "Train Accuracy: 0.6987\n",
      "Test Accuracy: 0.6200\n",
      "------------------------- layer 2 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.4256\n",
      "Train Accuracy: 0.7075\n",
      "Test Accuracy: 0.7000\n",
      "------------------------- layer 2 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6302\n",
      "Train Accuracy: 0.6675\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 2 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.6056\n",
      "Train Accuracy: 0.6725\n",
      "Test Accuracy: 0.6300\n",
      "------------------------- layer 2 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6090\n",
      "Train Accuracy: 0.6212\n",
      "Test Accuracy: 0.6200\n",
      "------------------------- layer 2 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.6616\n",
      "Train Accuracy: 0.6625\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 2 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.4759\n",
      "Train Accuracy: 0.6675\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 2 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5028\n",
      "Train Accuracy: 0.7212\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 2 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.5935\n",
      "Train Accuracy: 0.6350\n",
      "Test Accuracy: 0.6150\n",
      "------------------------- layer 2 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.6011\n",
      "Train Accuracy: 0.7037\n",
      "Test Accuracy: 0.7150\n",
      "------------------------- layer 2 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5621\n",
      "Train Accuracy: 0.7188\n",
      "Test Accuracy: 0.7000\n",
      "------------------------- layer 2 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.5987\n",
      "Train Accuracy: 0.6575\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 3 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.5212\n",
      "Train Accuracy: 0.7188\n",
      "Test Accuracy: 0.7650\n",
      "------------------------- layer 3 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6864\n",
      "Train Accuracy: 0.6663\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 3 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6134\n",
      "Train Accuracy: 0.6675\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 3 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5365\n",
      "Train Accuracy: 0.6750\n",
      "Test Accuracy: 0.6200\n",
      "------------------------- layer 3 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.5619\n",
      "Train Accuracy: 0.7075\n",
      "Test Accuracy: 0.6800\n",
      "------------------------- layer 3 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.4974\n",
      "Train Accuracy: 0.7275\n",
      "Test Accuracy: 0.6950\n",
      "------------------------- layer 3 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.5340\n",
      "Train Accuracy: 0.6650\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 3 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5049\n",
      "Train Accuracy: 0.6913\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 3 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.5851\n",
      "Train Accuracy: 0.6462\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 3 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5607\n",
      "Train Accuracy: 0.6462\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 3 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.6347\n",
      "Train Accuracy: 0.6913\n",
      "Test Accuracy: 0.6050\n",
      "------------------------- layer 3 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.4634\n",
      "Train Accuracy: 0.6725\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 4 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.7401\n",
      "Train Accuracy: 0.6425\n",
      "Test Accuracy: 0.6000\n",
      "------------------------- layer 4 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.5518\n",
      "Train Accuracy: 0.6737\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 4 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6599\n",
      "Train Accuracy: 0.6675\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 4 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5782\n",
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 4 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6285\n",
      "Train Accuracy: 0.7075\n",
      "Test Accuracy: 0.6850\n",
      "------------------------- layer 4 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.5345\n",
      "Train Accuracy: 0.6700\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 4 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.5155\n",
      "Train Accuracy: 0.7025\n",
      "Test Accuracy: 0.6500\n",
      "------------------------- layer 4 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5340\n",
      "Train Accuracy: 0.6900\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 4 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.5135\n",
      "Train Accuracy: 0.7275\n",
      "Test Accuracy: 0.6800\n",
      "------------------------- layer 4 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5781\n",
      "Train Accuracy: 0.7175\n",
      "Test Accuracy: 0.6650\n",
      "------------------------- layer 4 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5614\n",
      "Train Accuracy: 0.7037\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 4 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.6773\n",
      "Train Accuracy: 0.7388\n",
      "Test Accuracy: 0.7300\n",
      "------------------------- layer 5 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.4637\n",
      "Train Accuracy: 0.7275\n",
      "Test Accuracy: 0.7000\n",
      "------------------------- layer 5 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.5811\n",
      "Train Accuracy: 0.7550\n",
      "Test Accuracy: 0.6850\n",
      "------------------------- layer 5 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.5565\n",
      "Train Accuracy: 0.6800\n",
      "Test Accuracy: 0.6600\n",
      "------------------------- layer 5 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5476\n",
      "Train Accuracy: 0.6825\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 5 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.5988\n",
      "Train Accuracy: 0.6725\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 5 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.5108\n",
      "Train Accuracy: 0.7425\n",
      "Test Accuracy: 0.7100\n",
      "------------------------- layer 5 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.5518\n",
      "Train Accuracy: 0.6663\n",
      "Test Accuracy: 0.6100\n",
      "------------------------- layer 5 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5746\n",
      "Train Accuracy: 0.6575\n",
      "Test Accuracy: 0.5800\n",
      "------------------------- layer 5 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6727\n",
      "Train Accuracy: 0.7212\n",
      "Test Accuracy: 0.6850\n",
      "------------------------- layer 5 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.4641\n",
      "Train Accuracy: 0.7325\n",
      "Test Accuracy: 0.7050\n",
      "------------------------- layer 5 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.7078\n",
      "Train Accuracy: 0.6737\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 5 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.6603\n",
      "Train Accuracy: 0.6687\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 6 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.4946\n",
      "Train Accuracy: 0.6987\n",
      "Test Accuracy: 0.7300\n",
      "------------------------- layer 6 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6927\n",
      "Train Accuracy: 0.6438\n",
      "Test Accuracy: 0.6300\n",
      "------------------------- layer 6 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.4359\n",
      "Train Accuracy: 0.7550\n",
      "Test Accuracy: 0.7250\n",
      "------------------------- layer 6 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5800\n",
      "Train Accuracy: 0.7225\n",
      "Test Accuracy: 0.6750\n",
      "------------------------- layer 6 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.5263\n",
      "Train Accuracy: 0.7275\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 6 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.7269\n",
      "Train Accuracy: 0.6750\n",
      "Test Accuracy: 0.7250\n",
      "------------------------- layer 6 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.6256\n",
      "Train Accuracy: 0.7562\n",
      "Test Accuracy: 0.7450\n",
      "------------------------- layer 6 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.4767\n",
      "Train Accuracy: 0.7475\n",
      "Test Accuracy: 0.7200\n",
      "------------------------- layer 6 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.4829\n",
      "Train Accuracy: 0.6700\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 6 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.4605\n",
      "Train Accuracy: 0.7362\n",
      "Test Accuracy: 0.6850\n",
      "------------------------- layer 6 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5662\n",
      "Train Accuracy: 0.7688\n",
      "Test Accuracy: 0.7450\n",
      "------------------------- layer 6 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.4609\n",
      "Train Accuracy: 0.7063\n",
      "Test Accuracy: 0.6950\n",
      "------------------------- layer 7 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.7430\n",
      "Train Accuracy: 0.6775\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 7 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.5341\n",
      "Train Accuracy: 0.6963\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 7 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6684\n",
      "Train Accuracy: 0.7212\n",
      "Test Accuracy: 0.6100\n",
      "------------------------- layer 7 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5747\n",
      "Train Accuracy: 0.7075\n",
      "Test Accuracy: 0.7050\n",
      "------------------------- layer 7 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.5394\n",
      "Train Accuracy: 0.6737\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 7 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.6677\n",
      "Train Accuracy: 0.6637\n",
      "Test Accuracy: 0.5500\n",
      "------------------------- layer 7 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.5049\n",
      "Train Accuracy: 0.7238\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 7 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.6515\n",
      "Train Accuracy: 0.7350\n",
      "Test Accuracy: 0.7050\n",
      "------------------------- layer 7 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.5041\n",
      "Train Accuracy: 0.7025\n",
      "Test Accuracy: 0.6850\n",
      "------------------------- layer 7 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5298\n",
      "Train Accuracy: 0.7087\n",
      "Test Accuracy: 0.6650\n",
      "------------------------- layer 7 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.6427\n",
      "Train Accuracy: 0.6763\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 7 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.5393\n",
      "Train Accuracy: 0.7338\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 8 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.6079\n",
      "Train Accuracy: 0.6613\n",
      "Test Accuracy: 0.6300\n",
      "------------------------- layer 8 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6444\n",
      "Train Accuracy: 0.6787\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 8 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6051\n",
      "Train Accuracy: 0.6813\n",
      "Test Accuracy: 0.6500\n",
      "------------------------- layer 8 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.4484\n",
      "Train Accuracy: 0.7113\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 8 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6872\n",
      "Train Accuracy: 0.6613\n",
      "Test Accuracy: 0.6150\n",
      "------------------------- layer 8 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.4791\n",
      "Train Accuracy: 0.7500\n",
      "Test Accuracy: 0.6650\n",
      "------------------------- layer 8 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.6157\n",
      "Train Accuracy: 0.6950\n",
      "Test Accuracy: 0.6400\n",
      "------------------------- layer 8 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.5508\n",
      "Train Accuracy: 0.6800\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 8 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6114\n",
      "Train Accuracy: 0.6887\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 8 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.4561\n",
      "Train Accuracy: 0.7150\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 8 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5968\n",
      "Train Accuracy: 0.7200\n",
      "Test Accuracy: 0.6700\n",
      "------------------------- layer 8 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.5841\n",
      "Train Accuracy: 0.6250\n",
      "Test Accuracy: 0.5600\n",
      "------------------------- layer 9 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.4795\n",
      "Train Accuracy: 0.6575\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 9 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.5650\n",
      "Train Accuracy: 0.6538\n",
      "Test Accuracy: 0.6350\n",
      "------------------------- layer 9 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6277\n",
      "Train Accuracy: 0.6400\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 9 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.5169\n",
      "Train Accuracy: 0.7063\n",
      "Test Accuracy: 0.6550\n",
      "------------------------- layer 9 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.4861\n",
      "Train Accuracy: 0.7375\n",
      "Test Accuracy: 0.6150\n",
      "------------------------- layer 9 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.6247\n",
      "Train Accuracy: 0.6512\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 9 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.8252\n",
      "Train Accuracy: 0.6300\n",
      "Test Accuracy: 0.5500\n",
      "------------------------- layer 9 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.7165\n",
      "Train Accuracy: 0.6550\n",
      "Test Accuracy: 0.6650\n",
      "------------------------- layer 9 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6390\n",
      "Train Accuracy: 0.6488\n",
      "Test Accuracy: 0.5500\n",
      "------------------------- layer 9 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5815\n",
      "Train Accuracy: 0.6488\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 9 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.6255\n",
      "Train Accuracy: 0.6562\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 9 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.6552\n",
      "Train Accuracy: 0.7013\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 10 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.5662\n",
      "Train Accuracy: 0.6400\n",
      "Test Accuracy: 0.5000\n",
      "------------------------- layer 10 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.5405\n",
      "Train Accuracy: 0.6325\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 10 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6005\n",
      "Train Accuracy: 0.6525\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 10 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.6469\n",
      "Train Accuracy: 0.6100\n",
      "Test Accuracy: 0.4850\n",
      "------------------------- layer 10 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.5698\n",
      "Train Accuracy: 0.6375\n",
      "Test Accuracy: 0.6000\n",
      "------------------------- layer 10 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.5341\n",
      "Train Accuracy: 0.6525\n",
      "Test Accuracy: 0.6250\n",
      "------------------------- layer 10 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.7176\n",
      "Train Accuracy: 0.6325\n",
      "Test Accuracy: 0.5450\n",
      "------------------------- layer 10 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.6242\n",
      "Train Accuracy: 0.6725\n",
      "Test Accuracy: 0.6050\n",
      "------------------------- layer 10 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6581\n",
      "Train Accuracy: 0.6600\n",
      "Test Accuracy: 0.5600\n",
      "------------------------- layer 10 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.5471\n",
      "Train Accuracy: 0.6150\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 10 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5546\n",
      "Train Accuracy: 0.6538\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 10 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.6819\n",
      "Train Accuracy: 0.6362\n",
      "Test Accuracy: 0.6100\n",
      "------------------------- layer 11 head 0 -------------------------\n",
      "Epoch: 200, Loss: 0.6925\n",
      "Train Accuracy: 0.6225\n",
      "Test Accuracy: 0.5900\n",
      "------------------------- layer 11 head 1 -------------------------\n",
      "Epoch: 200, Loss: 0.6040\n",
      "Train Accuracy: 0.6012\n",
      "Test Accuracy: 0.5250\n",
      "------------------------- layer 11 head 2 -------------------------\n",
      "Epoch: 200, Loss: 0.6029\n",
      "Train Accuracy: 0.6388\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 11 head 3 -------------------------\n",
      "Epoch: 200, Loss: 0.7385\n",
      "Train Accuracy: 0.6162\n",
      "Test Accuracy: 0.5000\n",
      "------------------------- layer 11 head 4 -------------------------\n",
      "Epoch: 200, Loss: 0.6185\n",
      "Train Accuracy: 0.6350\n",
      "Test Accuracy: 0.5550\n",
      "------------------------- layer 11 head 5 -------------------------\n",
      "Epoch: 200, Loss: 0.7205\n",
      "Train Accuracy: 0.6238\n",
      "Test Accuracy: 0.5100\n",
      "------------------------- layer 11 head 6 -------------------------\n",
      "Epoch: 200, Loss: 0.6397\n",
      "Train Accuracy: 0.6388\n",
      "Test Accuracy: 0.5150\n",
      "------------------------- layer 11 head 7 -------------------------\n",
      "Epoch: 200, Loss: 0.6596\n",
      "Train Accuracy: 0.6250\n",
      "Test Accuracy: 0.5700\n",
      "------------------------- layer 11 head 8 -------------------------\n",
      "Epoch: 200, Loss: 0.6872\n",
      "Train Accuracy: 0.6438\n",
      "Test Accuracy: 0.5950\n",
      "------------------------- layer 11 head 9 -------------------------\n",
      "Epoch: 200, Loss: 0.6452\n",
      "Train Accuracy: 0.6562\n",
      "Test Accuracy: 0.4800\n",
      "------------------------- layer 11 head 10 -------------------------\n",
      "Epoch: 200, Loss: 0.5424\n",
      "Train Accuracy: 0.6813\n",
      "Test Accuracy: 0.5650\n",
      "------------------------- layer 11 head 11 -------------------------\n",
      "Epoch: 200, Loss: 0.5662\n",
      "Train Accuracy: 0.6475\n",
      "Test Accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "train_accs = {}\n",
    "test_accs = {}\n",
    "\n",
    "for layer in tqdm(range(12)):\n",
    "    train_accs[layer] = {}\n",
    "    test_accs[layer] = {}\n",
    "    for head in range(12):\n",
    "        probe = GCNProbe(64, 2).to(\"cuda\")\n",
    "\n",
    "        optimizer = torch.optim.Adam(probe.parameters(), lr=0.01)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if train_mask[i]]\n",
    "        test_dataset = [all_graphs[layer][head][i].to(\"cuda\") for i in range(len(all_graphs[layer][head])) if test_mask[i]]\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        for epoch in range(1, 201):\n",
    "            loss = train(probe, optimizer, criterion, train_loader)\n",
    "            train_acc = test(probe, train_loader)\n",
    "\n",
    "            # if (epoch - 1) % 20 == 0:\n",
    "            #     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "            #     print(f'Train Accuracy: {train_acc:.4f}')\n",
    "\n",
    "        print(\"-\" * 25 + f\" layer {layer} head {head} \" + \"-\" * 25)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        print(f'Train Accuracy: {train_acc:.4f}')\n",
    "        \n",
    "        test_acc = test(probe, test_loader)\n",
    "        print(f'Test Accuracy: {test_acc:.4f}')\n",
    "        \n",
    "        train_accs[layer][head] = train_acc\n",
    "        test_accs[layer][head] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c63fb-2a62-4f08-b0a0-36a39c2e6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_utils import heatmap, annotate_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "score_matrix = []\n",
    "\n",
    "for layer in range(12):\n",
    "    score_matrix.append([])\n",
    "    for head in range(12):\n",
    "        score_matrix[layer].append(test_accs[layer][head])\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "im, cbar = heatmap(np.array(score_matrix), [f\"Layer {i + 1}\" for i in range(12)], [f\"H {i + 1}\" for i in range(12)],\n",
    "           cmap=\"bwr\")\n",
    "\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(18)\n",
    "\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.2f} \", fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44bde5-4f40-4dd8-96af-b8ac81637f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b9c45-13a4-4a94-81cb-1870a99f2e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diffusion]",
   "language": "python",
   "name": "conda-env-.conda-diffusion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
